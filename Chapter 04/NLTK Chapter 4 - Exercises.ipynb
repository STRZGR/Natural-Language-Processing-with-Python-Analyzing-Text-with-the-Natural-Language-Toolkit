{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 4\n",
    "\n",
    "## Writing Structured Programs\n",
    "\n",
    "*The html version of this chapter in the NLTK book is available [here](https://www.nltk.org/book/ch04.html#exercises \"Ch04 Exercises\").*\n",
    "\n",
    "### 4.11   Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###### 1. \n",
    "\n",
    "☼ Find out more about sequence objects using Python's help facility. In the interpreter, type `help(str)`, `help(list)`, and `help(tuple)`. This will give you a full list of the functions supported by each type. Some functions have special names flanked with underscore; as the help documentation shows, each such function corresponds to something more familiar. For example `x.__getitem__(y)` is just a long-winded way of saying `x[y]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class str in module builtins:\n",
      "\n",
      "class str(object)\n",
      " |  str(object='') -> str\n",
      " |  str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
      " |  \n",
      " |  Create a new string object from the given object. If encoding or\n",
      " |  errors is specified, then the object must expose a data buffer\n",
      " |  that will be decoded using the given encoding and error handler.\n",
      " |  Otherwise, returns the result of object.__str__() (if defined)\n",
      " |  or repr(object).\n",
      " |  encoding defaults to sys.getdefaultencoding().\n",
      " |  errors defaults to 'strict'.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __format__(self, format_spec, /)\n",
      " |      Return a formatted version of the string as described by format_spec.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __sizeof__(self, /)\n",
      " |      Return the size of the string in memory, in bytes.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(self, /)\n",
      " |      Return a capitalized version of the string.\n",
      " |      \n",
      " |      More specifically, make the first character have upper case and the rest lower\n",
      " |      case.\n",
      " |  \n",
      " |  casefold(self, /)\n",
      " |      Return a version of the string suitable for caseless comparisons.\n",
      " |  \n",
      " |  center(self, width, fillchar=' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  count(...)\n",
      " |      S.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of substring sub in\n",
      " |      string S[start:end].  Optional arguments start and end are\n",
      " |      interpreted as in slice notation.\n",
      " |  \n",
      " |  encode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Encode the string using the codec registered for encoding.\n",
      " |      \n",
      " |      encoding\n",
      " |        The encoding in which to encode the string.\n",
      " |      errors\n",
      " |        The error handling scheme to use for encoding errors.\n",
      " |        The default is 'strict' meaning that encoding errors raise a\n",
      " |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
      " |        'xmlcharrefreplace' as well as any other name registered with\n",
      " |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      S.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      suffix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |      \n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      S.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  format(...)\n",
      " |      S.format(*args, **kwargs) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  format_map(...)\n",
      " |      S.format_map(mapping) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from mapping.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  index(...)\n",
      " |      S.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found, \n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  isalnum(self, /)\n",
      " |      Return True if the string is an alpha-numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isalpha(self, /)\n",
      " |      Return True if the string is an alphabetic string, False otherwise.\n",
      " |      \n",
      " |      A string is alphabetic if all characters in the string are alphabetic and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isascii(self, /)\n",
      " |      Return True if all characters in the string are ASCII, False otherwise.\n",
      " |      \n",
      " |      ASCII characters have code points in the range U+0000-U+007F.\n",
      " |      Empty string is ASCII too.\n",
      " |  \n",
      " |  isdecimal(self, /)\n",
      " |      Return True if the string is a decimal string, False otherwise.\n",
      " |      \n",
      " |      A string is a decimal string if all characters in the string are decimal and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isdigit(self, /)\n",
      " |      Return True if the string is a digit string, False otherwise.\n",
      " |      \n",
      " |      A string is a digit string if all characters in the string are digits and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isidentifier(self, /)\n",
      " |      Return True if the string is a valid Python identifier, False otherwise.\n",
      " |      \n",
      " |      Use keyword.iskeyword() to test for reserved identifiers such as \"def\" and\n",
      " |      \"class\".\n",
      " |  \n",
      " |  islower(self, /)\n",
      " |      Return True if the string is a lowercase string, False otherwise.\n",
      " |      \n",
      " |      A string is lowercase if all cased characters in the string are lowercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  isnumeric(self, /)\n",
      " |      Return True if the string is a numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is numeric if all characters in the string are numeric and there is at\n",
      " |      least one character in the string.\n",
      " |  \n",
      " |  isprintable(self, /)\n",
      " |      Return True if the string is printable, False otherwise.\n",
      " |      \n",
      " |      A string is printable if all of its characters are considered printable in\n",
      " |      repr() or if it is empty.\n",
      " |  \n",
      " |  isspace(self, /)\n",
      " |      Return True if the string is a whitespace string, False otherwise.\n",
      " |      \n",
      " |      A string is whitespace if all characters in the string are whitespace and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  istitle(self, /)\n",
      " |      Return True if the string is a title-cased string, False otherwise.\n",
      " |      \n",
      " |      In a title-cased string, upper- and title-case characters may only\n",
      " |      follow uncased characters and lowercase characters only cased ones.\n",
      " |  \n",
      " |  isupper(self, /)\n",
      " |      Return True if the string is an uppercase string, False otherwise.\n",
      " |      \n",
      " |      A string is uppercase if all cased characters in the string are uppercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  join(self, iterable, /)\n",
      " |      Concatenate any number of strings.\n",
      " |      \n",
      " |      The string whose method is called is inserted in between each given string.\n",
      " |      The result is returned as a new string.\n",
      " |      \n",
      " |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      " |  \n",
      " |  ljust(self, width, fillchar=' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  lower(self, /)\n",
      " |      Return a copy of the string converted to lowercase.\n",
      " |  \n",
      " |  lstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  partition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string.  If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing the original string\n",
      " |      and two empty strings.\n",
      " |  \n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |      \n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |      \n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      S.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      S.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  rjust(self, width, fillchar=' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
      " |      and the original string.\n",
      " |  \n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |        sep\n",
      " |          The delimiter according which to split the string.\n",
      " |          None (the default value) means split according to any whitespace,\n",
      " |          and discard empty strings from the result.\n",
      " |        maxsplit\n",
      " |          Maximum number of splits to do.\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Splits are done starting at the end of the string and working to the front.\n",
      " |  \n",
      " |  rstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |      sep\n",
      " |        The delimiter according which to split the string.\n",
      " |        None (the default value) means split according to any whitespace,\n",
      " |        and discard empty strings from the result.\n",
      " |      maxsplit\n",
      " |        Maximum number of splits to do.\n",
      " |        -1 (the default value) means no limit.\n",
      " |  \n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the string, breaking at line boundaries.\n",
      " |      \n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      S.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      prefix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  strip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading and trailing whitespace remove.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  swapcase(self, /)\n",
      " |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
      " |  \n",
      " |  title(self, /)\n",
      " |      Return a version of the string where each word is titlecased.\n",
      " |      \n",
      " |      More specifically, words start with uppercased characters and all remaining\n",
      " |      cased characters have lower case.\n",
      " |  \n",
      " |  translate(self, table, /)\n",
      " |      Replace each character in the string using the given translation table.\n",
      " |      \n",
      " |        table\n",
      " |          Translation table, which must be a mapping of Unicode ordinals to\n",
      " |          Unicode ordinals, strings, or None.\n",
      " |      \n",
      " |      The table must implement lookup/indexing via __getitem__, for instance a\n",
      " |      dictionary or list.  If this operation raises LookupError, the character is\n",
      " |      left untouched.  Characters mapped to None are deleted.\n",
      " |  \n",
      " |  upper(self, /)\n",
      " |      Return a copy of the string converted to uppercase.\n",
      " |  \n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |      \n",
      " |      The string is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  maketrans(x, y=None, z=None, /)\n",
      " |      Return a translation table usable for str.translate().\n",
      " |      \n",
      " |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      " |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      " |      Character keys will be then converted to ordinals.\n",
      " |      If there are two arguments, they must be strings of equal length, and\n",
      " |      in the resulting dictionary, each character in x will be mapped to the\n",
      " |      character at the same position in y. If there is a third argument, it\n",
      " |      must be a string, whose characters will be mapped to None in the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class list in module builtins:\n",
      "\n",
      "class list(object)\n",
      " |  list(iterable=(), /)\n",
      " |  \n",
      " |  Built-in mutable sequence.\n",
      " |  \n",
      " |  If no argument is given, the constructor creates a new empty list.\n",
      " |  The argument must be an iterable if specified.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __iadd__(self, value, /)\n",
      " |      Implement self+=value.\n",
      " |  \n",
      " |  __imul__(self, value, /)\n",
      " |      Implement self*=value.\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __reversed__(self, /)\n",
      " |      Return a reverse iterator over the list.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __setitem__(self, key, value, /)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __sizeof__(self, /)\n",
      " |      Return the size of the list in memory, in bytes.\n",
      " |  \n",
      " |  append(self, object, /)\n",
      " |      Append object to the end of the list.\n",
      " |  \n",
      " |  clear(self, /)\n",
      " |      Remove all items from list.\n",
      " |  \n",
      " |  copy(self, /)\n",
      " |      Return a shallow copy of the list.\n",
      " |  \n",
      " |  count(self, value, /)\n",
      " |      Return number of occurrences of value.\n",
      " |  \n",
      " |  extend(self, iterable, /)\n",
      " |      Extend list by appending elements from the iterable.\n",
      " |  \n",
      " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      " |      Return first index of value.\n",
      " |      \n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  insert(self, index, object, /)\n",
      " |      Insert object before index.\n",
      " |  \n",
      " |  pop(self, index=-1, /)\n",
      " |      Remove and return item at index (default last).\n",
      " |      \n",
      " |      Raises IndexError if list is empty or index is out of range.\n",
      " |  \n",
      " |  remove(self, value, /)\n",
      " |      Remove first occurrence of value.\n",
      " |      \n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  reverse(self, /)\n",
      " |      Reverse *IN PLACE*.\n",
      " |  \n",
      " |  sort(self, /, *, key=None, reverse=False)\n",
      " |      Stable sort *IN PLACE*.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class tuple in module builtins:\n",
      "\n",
      "class tuple(object)\n",
      " |  tuple(iterable=(), /)\n",
      " |  \n",
      " |  Built-in immutable sequence.\n",
      " |  \n",
      " |  If no argument is given, the constructor returns an empty tuple.\n",
      " |  If iterable is specified the tuple is initialized from iterable's items.\n",
      " |  \n",
      " |  If the argument is a tuple, the return value is the same object.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(self, /)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  count(self, value, /)\n",
      " |      Return number of occurrences of value.\n",
      " |  \n",
      " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      " |      Return first index of value.\n",
      " |      \n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. \n",
    "\n",
    "☼ Identify three operations that can be performed on both tuples and lists. Identify three list operations that cannot be performed on tuples. Name a context where using a list instead of a tuple generates a Python error.\n",
    "\n",
    "*Operations that can be performed on both tuples and lists:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'count', 'index']"
     ]
    }
   ],
   "source": [
    "print([x for x in dir(list) if x in dir(tuple)], end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Operations that can be performed on lists, but not tuples:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__delitem__', '__iadd__', '__imul__', '__reversed__', '__setitem__', 'append', 'clear', 'copy', 'extend', 'insert', 'pop', 'remove', 'reverse', 'sort']"
     ]
    }
   ],
   "source": [
    "print([x for x in dir(list) if x not in dir(tuple)], end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Trying to use a list as a key in a dictionary will not work, but it's possible with a tuple:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (\"Snugglebunnies\")\n",
    "b = [\"Basselopes\"]\n",
    "\n",
    "c = {a: \"N\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Saved as markdown because having a cell that throws an error will cause my notebook to go higgledy piddledy:*\n",
    "\n",
    "```\n",
    "c = {b: \"N\"}\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-17-ee5632d64820> in <module>\n",
    "----> 1 c = {b: \"N\"}\n",
    "\n",
    "TypeError: unhashable type: 'list'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is because tuples are hashable, but lists are not:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6857707573350195552"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "hash(b)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-19-ad85d8b55702> in <module>\n",
    "----> 1 hash(b)\n",
    "\n",
    "TypeError: unhashable type: 'list'\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. \n",
    "\n",
    "☼ Find out how to create a tuple consisting of a single item. There are at least two ways to do this.\n",
    "\n",
    "*Add a common after a single value, or create a list with a single value, and use `tuple` to convert this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1, \n",
    "\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tuple([1])\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. \n",
    "\n",
    "☼ Create a list `words = ['is', 'NLP', 'fun', '?']`. Use a series of assignment statements (e.g. `words[1] = words[2]`) and a temporary variable `tmp` to transform this list into the list `['NLP', 'is', 'fun', '!']`. Now do the same transformation using tuple assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "tmp = words[0]\n",
    "words[0] = words[1]\n",
    "words[1] = tmp\n",
    "words[3] = '!'\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "words[1], words[0], words[3] = words[0], words[1], \"!\"\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.\n",
    "\n",
    "☼ Read about the built-in comparison function `cmp`, by typing `help(cmp)`. How does it differ in behavior from the comparison operators?\n",
    "\n",
    "*`cmp` has been deprecated.  Get with the times, authors!*\n",
    "\n",
    "```\n",
    "help(cmp)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "<ipython-input-29-6cc5f65683db> in <module>\n",
    "----> 1 help(cmp)\n",
    "\n",
    "NameError: name 'cmp' is not defined\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. \n",
    "\n",
    "☼ Does the method for creating a sliding window of n-grams behave correctly for the two limiting cases: $n$ = 1, and $n$ = `len(sent)`?\n",
    "\n",
    "*No.  $n$ = 1 will just return __unigrams__, i.e., the individual words which comprised the sentence.  $n$ = `len(sent)` will just return the entire list:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'], ['dog'], ['gave'], ['John'], ['the'], ['newspaper']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 1\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    ">>> n = len(sent)\n",
    ">>> [sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.\n",
    "\n",
    "☼ We pointed out that when empty strings and empty lists occur in the condition part of an `if` clause, they evaluate to `False`. In this case, they are said to be occurring in a Boolean context. Experiment with different kind of non-Boolean expressions in Boolean contexts, and see whether they evaluate as `True` or `False`.\n",
    "\n",
    "*With the exception of 0, all numbers evaluate as True.  Even `float('Inf')`, `-float('Inf')`, and `float('NaN')`. All strings evaluate as True, except for the empty string. Empty lists and tuples will evaluate as False.  `None` evaluates as false, but `None` in a list or a tuple evaluates as True.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 evaluates as False\n",
      "1 evaluates as True\n",
      "-1 evaluates as True\n",
      "inf evaluates as True\n",
      "-inf evaluates as True\n",
      "nan evaluates as True\n",
      "0 evaluates as True\n",
      "1 evaluates as True\n",
      " evaluates as False\n",
      "[] evaluates as False\n",
      "Fahrvergnügen evaluates as True\n",
      "3.1415 evaluates as True\n",
      "None evaluates as False\n",
      "[None] evaluates as True\n",
      "() evaluates as False\n",
      "(None,) evaluates as True\n"
     ]
    }
   ],
   "source": [
    "cands = [0, 1, -1, float('Inf'), -float('Inf'), float('NaN'), \"0\", \"1\", \"\", [], \n",
    "         \"Fahrvergnügen\", 3.1415, None, [None], tuple([]), tuple([None])]\n",
    "\n",
    "for c in cands:\n",
    "    if c:\n",
    "        print(\"{} evaluates as True\".format(c))\n",
    "    else:\n",
    "        print(\"{} evaluates as False\".format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. \n",
    "\n",
    "☼ Use the inequality operators to compare strings, e.g. `'Monty' < 'Python'`. What happens when you do `'Z' < 'a'`? Try pairs of strings which have a common prefix, e.g. `'Monty' < 'Montague'`. Read up on \"lexicographical sort\" in order to understand what is going on here. Try comparing structured objects, e.g. `('Monty', 1) < ('Monty', 2)`. Does this behave as expected?\n",
    "\n",
    "*In lexicographical sort, only the first index in both items is compared.  Since 'M' comes before 'P', the rest of the string is ignored.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty' < 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'M' < 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty' < 'P'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Uppercase letters are considered as coming 'before' lowercase ones.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Z' < 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*'Monty' and 'Montague' have the same first four elements.  Since 'y' comes after 'a', the comparison evaluates as `False`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty' < 'Montague'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As the first elements in both tuples are identical, the second element is compared, and one is indeed less than 2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('Monty', 1) < ('Monty', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Carrying on that logic a bit further:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('Monty', 1, 1, 1, 5) < ('Monty', 1, 1, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.\n",
    "\n",
    "☼ Write code that removes whitespace at the beginning and end of a string, and normalizes whitespace between words to be a single space character.\n",
    "\n",
    "* 1. do this task using `split()` and `join()`\n",
    "* 2. do this task using regular expression substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a really inconsistent use of whitespace.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"    this    is   a really inconsistent          use  of     whitespace.      \"\n",
    "sent = sent.split()\n",
    "' '.join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a really inconsistent use of whitespace.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"    this    is   a really inconsistent          use  of     whitespace.      \"\n",
    "sent = re.sub(r'^\\s*|\\s*$', '', sent)\n",
    "sent = re.sub(r'\\s+', ' ', sent)\n",
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.\n",
    "\n",
    "☼ Write a program to sort words by length. Define a helper function `cmp_len` which uses the `cmp` comparison function on word lengths.\n",
    "\n",
    "*`cmp` is still deprecated, so I'll only do the first part of this exercise.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_words_by_length(text):\n",
    "    \"\"\"\n",
    "    Returns a list, sorted from shortest to longest,\n",
    "    of words in text.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [w for _, w in sorted([(len(w), w) for w in text.split()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'of', 'are', 'the', 'this', 'words', 'mostly', 'unique', 'lengths', 'sentence', 'character']"
     ]
    }
   ],
   "source": [
    "sent = 'the words in this sentence are mostly of unique character lengths'\n",
    "\n",
    "print(sort_words_by_length(sent), end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.\n",
    "\n",
    "◑ Create a list of words and store it in a variable `sent1`. Now assign `sent2 = sent1`. Modify one of the items in `sent1` and verify that `sent2` has changed.\n",
    "\n",
    "* a. Now try the same exercise but instead assign `sent2 = sent1[:]`. Modify sent1 again and see what happens to `sent2`. Explain.\n",
    "* b. Now define `text1` to be a list of lists of strings (e.g. to represent a text consisting of multiple sentences. Now assign `text2 = text1[:]`, assign a new value to one of the words, e.g. `text1[1][1] = 'Monty'`. Check what this did to `text2`. Explain.\n",
    "* c. Load Python's `deepcopy()` function (i.e. `from copy import deepcopy`), consult its documentation, and test that it makes a fresh copy of any object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mares', 'doats', 'and', 'dozy', 'doats', 'and', 'liddle', 'lamzy', 'divey', 'A', 'kiddley', 'divey', 'too,', \"wouldn't\", 'you?']"
     ]
    }
   ],
   "source": [
    "sent = \"Mairzy doats and dozy doats and liddle lamzy divey \" \\\n",
    "        \"A kiddley divey too, wouldn't you?\"\n",
    "sent1 = sent.split()\n",
    "sent2 = sent1\n",
    "sent1[0] = \"Mares\"\n",
    "print(sent2, end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__a.__ Using `[:]` causes `sent1` to be shallow copied, so changes aren't replicated in `sent2`.  I.e., it's a reference to a copy of the list, and not the original list.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mairzy', 'doats', 'and', 'dozy', 'doats', 'and', 'liddle', 'lamzy', 'divey', 'A', 'kiddley', 'divey', 'too,', \"wouldn't\", 'you?']"
     ]
    }
   ],
   "source": [
    "sent = \"Mairzy doats and dozy doats and liddle lamzy divey \" \\\n",
    "        \"A kiddley divey too, wouldn't you?\"\n",
    "sent1 = sent.split()\n",
    "sent2 = sent1[:]\n",
    "sent1[0] = \"Mares\"\n",
    "print(sent2, end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__b.__ Now the change is permeated.  It appears a shallow copy of a list of lists is just a copy of the references of the lists.  I.e., if one of the original lists is changed, the changed is reflected.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mairzy', 'doats', 'and', 'dozy', 'doats', 'and', 'liddle', 'lamzy', 'divey'], ['A', 'Monty', 'divey', 'too,', \"wouldn't\", 'you?']]"
     ]
    }
   ],
   "source": [
    "sentA = \"Mairzy doats and dozy doats and liddle lamzy divey\"\n",
    "sentB = \"A kiddley divey too, wouldn't you?\"\n",
    "\n",
    "text1 = [sentA.split(), sentB.split()]\n",
    "text2 = text1[:]\n",
    "\n",
    "text1[1][1] = 'Monty'\n",
    "\n",
    "print(text2, end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we explicitly make shallow copies of the lists in the list of lists, then the changes won't be replicated:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mairzy', 'doats', 'and', 'dozy', 'doats', 'and', 'liddle', 'lamzy', 'divey'], ['A', 'kiddley', 'divey', 'too,', \"wouldn't\", 'you?']]"
     ]
    }
   ],
   "source": [
    "sentA = \"Mairzy doats and dozy doats and liddle lamzy divey\"\n",
    "sentB = \"A kiddley divey too, wouldn't you?\"\n",
    "\n",
    "text1 = [sentA.split(), sentB.split()]\n",
    "text2 = [text1[0][:], text1[1][:]]\n",
    "\n",
    "text1[1][1] = 'Monty'\n",
    "\n",
    "print(text2, end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__c.__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mairzy', 'doats', 'and', 'dozy', 'doats', 'and', 'liddle', 'lamzy', 'divey', 'A', 'kiddley', 'divey', 'too,', \"wouldn't\", 'you?']"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "sent = \"Mairzy doats and dozy doats and liddle lamzy divey \" \\\n",
    "        \"A kiddley divey too, wouldn't you?\"\n",
    "sent1 = sent.split()\n",
    "sent2 = deepcopy(sent1)\n",
    "sent1[0] = \"Mares\"\n",
    "print(sent2, end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. \n",
    "\n",
    "◑ Initialize an $n$-by-$m$ list of lists of empty strings using list multiplication, e.g. `word_table = [[''] * n] * m`. What happens when you set one of its values, e.g. `word_table[1][2] = \"hello\"`? Explain why this happens. Now write an expression using `range()` to construct a list of lists, and show that it does not have this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', '']]\n"
     ]
    }
   ],
   "source": [
    "m, n = 6, 7\n",
    "\n",
    "word_table = [[''] * n] * m\n",
    "pprint.pprint(word_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', '', 'hello', '', '', '', ''],\n",
      " ['', '', 'hello', '', '', '', ''],\n",
      " ['', '', 'hello', '', '', '', ''],\n",
      " ['', '', 'hello', '', '', '', ''],\n",
      " ['', '', 'hello', '', '', '', ''],\n",
      " ['', '', 'hello', '', '', '', '']]\n"
     ]
    }
   ],
   "source": [
    "word_table[1][2] = (\"hello\")\n",
    "pprint.pprint(word_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Above we have a copy of a list containing sublists. When we make a change to one of the sublists, the copy is replicated in all of the lists which have been created by copying it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', '']]\n"
     ]
    }
   ],
   "source": [
    "word_table = [['' for i in range(n)] for j in range(m)]\n",
    "pprint.pprint(word_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', '', '', '', '', '', ''],\n",
      " ['', '', 'hello', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', ''],\n",
      " ['', '', '', '', '', '', '']]\n"
     ]
    }
   ],
   "source": [
    "word_table[1][2] = (\"hello\")\n",
    "pprint.pprint(word_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this case, we're creating a brand new empty string for each of the iterations through $n$, and likewise through $m$.  As the strings are not copies of each other, changes in one are not reflected in the others.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. \n",
    "\n",
    "◑ Write code to initialize a two-dimensional array of sets called `word_vowels` and process a list of words, adding each word to `word_vowels[l][v]` where `l` is the length of the word and `v` is the number of vowels it contains.\n",
    "\n",
    "*If we follow the instructions literally and create an array of sets, both sets will come back sorted, and it is very likely that the $n$th item in the first set will not be the same as the $n$th item in the second.  I.e., a long word without many vowels would be represented towards the end of the first set, but towards the beginning of the second (and vice versa):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_length_word_number_vowels(text):\n",
    "    \"\"\"\n",
    "    Returns an array of two sets.  The first set comprises\n",
    "    the lengths of the words.  The second the number of vowels.\n",
    "    For the sake of simplicity, 'y' is not counted as a vowel.\n",
    "    Results are ordered from smallest to greatest.\n",
    "    \"\"\"\n",
    "    \n",
    "    word_vowels = [set(), set()]\n",
    "\n",
    "    for t in text:\n",
    "        word_vowels[0].add(len(t))\n",
    "        word_vowels[1].add(sum([1 for i in t if i.lower() in 'aeiou']))\n",
    "\n",
    "    return word_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{3, 5, 7, 34}, {1, 2, 4, 16}]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"supercalifragilisticexpialidocious\", \"eye\", \"Hawai'i\", \"draft\"]\n",
    "find_length_word_number_vowels(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using lists instead of sets will obviate this problem:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_length_word_number_vowels_by_order_of_appearance(text):\n",
    "    \"\"\"\n",
    "    Returns an array of two lists.  The first set comprises\n",
    "    the lengths of the words.  The second the number of vowels.\n",
    "    For the sake of simplicity, 'y' is not counted as a vowel.\n",
    "    Results are ordered by order of appearance of the original\n",
    "    word.\n",
    "    \"\"\"\n",
    "    \n",
    "    word_vowels = [[], []]\n",
    "\n",
    "    for t in text:\n",
    "        word_vowels[0].append(len(t))\n",
    "        \n",
    "        # taking advantage of the fact that `True` evaluates to 1\n",
    "        word_vowels[1].append(sum([1 for i in t if i.lower() in 'aeiou']))\n",
    "\n",
    "    return word_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[34, 3, 7, 5], [16, 2, 4, 1]]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_length_word_number_vowels_by_order_of_appearance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. \n",
    "\n",
    "◑ Write a function `novel10(text)` that prints any word that appeared in the last 10% of a text that had not been encountered earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novel10(text):\n",
    "    \"\"\"\n",
    "    Returns a set of words that appear for the first time\n",
    "    in the last 10% of a text.\n",
    "    \"\"\"\n",
    "\n",
    "    split = int(len(text) * .9)\n",
    "    first90, last10 = text[:split], text[split:]\n",
    "    novel90 = set(first90)\n",
    "\n",
    "    return set([i for i in last10 if i not in novel90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Mary Shelley's Frankenstein\n",
    "url = 'http://www.gutenberg.org/cache/epub/42324/pg42324.txt'\n",
    "\n",
    "frank = request.urlopen(url).read().decode('utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "frank = word_tokenize(frank)\n",
    "\n",
    "# used trial and error (and `index`) to find and remove\n",
    "# header and footer\n",
    "frank = frank[115:90732]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Converted results to a list so that I could use slicing to get the first 20 items:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['torch', 'later', 'wasting', '6375', 'lessening', 'Black', '2d', 'piercing', 'renounce', 'mole-hills', 'indecision', 'Cold', 'asseverations', 'irremediable', 'mutilated', 'repast', 'abortion', 'unquenched', 'rustling', 'boils']"
     ]
    }
   ],
   "source": [
    "print(list(novel10(frank))[:20], end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15.\n",
    "\n",
    "◑ Write a program that takes a sentence expressed as a single string, splits it and counts up the words. Get it to print out each word and the word's frequency, one per line, in alphabetical order.\n",
    "\n",
    "*Although it's not best practice stylistically, the instructions say to print everything, so I'm going to do that instead of returning a value:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def print_words_and_frequency(text):\n",
    "    \"\"\"\n",
    "    Counts the words in a text and prints out the\n",
    "    resulting table in alphabetical order.\n",
    "    \"\"\"\n",
    "\n",
    "    # tokenizer separates words from punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    words = [t.lower() for t in tokens if t.isalpha()]\n",
    "    \n",
    "    # get word counts from FreqDist\n",
    "    ordered = sorted(set([(w, v) for w, v in nltk.FreqDist(words).items()]))\n",
    "    \n",
    "    # get widths for pretty printing\n",
    "    # width of longest word\n",
    "    width = max([len(w) for w, _ in ordered]) + 2\n",
    "    # width of longest number\n",
    "    width_counts = max([len(str(v)) for _, v in ordered])\n",
    "    \n",
    "    # print everything\n",
    "    for w, v in ordered:\n",
    "        print(\"{}:{}{:>{}}\".format(w, ' ' * (width - len(w)), \n",
    "                                     v, width_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if:        1\n",
      "police:   12\n",
      "polices:   1\n",
      "the:       1\n",
      "who:       1\n"
     ]
    }
   ],
   "source": [
    "test = \"If police police police police, who polices the police police? \" \\\n",
    "       \"Police police police police police police.\"\n",
    "\n",
    "print_words_and_frequency(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:          2\n",
      "chuck:      2\n",
      "could:      1\n",
      "how:        1\n",
      "if:         1\n",
      "much:       1\n",
      "wood:       2\n",
      "woodchuck:  2\n",
      "would:      1\n"
     ]
    }
   ],
   "source": [
    "test = \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\"\n",
    "print_words_and_frequency(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16.\n",
    "\n",
    "◑ Read up on Gematria, a method for assigning numbers to words, and for mapping between words having the same number to discover the hidden meaning of texts (cf. [here](http://en.wikipedia.org/wiki/Gematria \"Wikipedia entry\"), or [here](http://essenes.net/gemcal.htm \"Gematria\")).\n",
    "\n",
    "* a. Write a function `gematria()` that sums the numerical values of the letters of a word, according to the letter values in `letter_vals`:\n",
    "\n",
    "``` \t\n",
    ">>> letter_vals = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':80, 'g':3, 'h':8,\n",
    "... 'i':10, 'j':10, 'k':20, 'l':30, 'm':40, 'n':50, 'o':70, 'p':80, 'q':100,\n",
    "... 'r':200, 's':300, 't':400, 'u':6, 'v':6, 'w':800, 'x':60, 'y':10, 'z':7}\n",
    "```\n",
    "\n",
    "* b. Process a corpus (e.g. `nltk.corpus.state_union`) and for each document, count how many of its words have the number 666.\n",
    "\n",
    "* c. Write a function `decode()` to process a text, randomly replacing words with their Gematria equivalents, in order to discover the \"hidden meaning\" of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_vals = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':80, 'g':3, 'h':8,\n",
    "       'i':10, 'j':10, 'k':20, 'l':30, 'm':40, 'n':50, 'o':70, 'p':80, 'q':100,\n",
    "       'r':200, 's':300, 't':400, 'u':6, 'v':6, 'w':800, 'x':60, 'y':10, 'z':7}\n",
    "\n",
    "def gematria(word, vals = letter_vals):\n",
    "    \"\"\"\n",
    "    Returns Gematria value of a word.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    word: Word to be converted.\n",
    "    vals: Dictionary of values for each letter.\n",
    "          Default is `letter_vals`.\n",
    "    \"\"\"\n",
    "    \n",
    "    return sum(vals[w.lower()] for w in word if w in vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__b.__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "su = nltk.corpus.state_union\n",
    "\n",
    "# for pretty printing later\n",
    "width = max([len(u[5:-4]) for u in su.fileids()])\n",
    "\n",
    "devil_words = [sum([1 for w in su.words(u) if gematria(w) == 666]) for u in su.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1945 Truman:      2\n",
      "1946 Truman:     20\n",
      "1947 Truman:      1\n",
      "1948 Truman:      3\n",
      "1949 Truman:      2\n",
      "1950 Truman:      1\n",
      "1951 Truman:      0\n",
      "1953 Eisenhower:  1\n",
      "1954 Eisenhower:  6\n",
      "1955 Eisenhower:  5\n",
      "1956 Eisenhower:  1\n",
      "1957 Eisenhower:  2\n",
      "1958 Eisenhower:  5\n",
      "1959 Eisenhower:  1\n",
      "1960 Eisenhower:  5\n",
      "1961 Kennedy:     0\n",
      "1962 Kennedy:     4\n",
      "1963 Johnson:     0\n",
      "1963 Kennedy:     3\n",
      "1964 Johnson:     1\n",
      "1965 Johnson-1:   0\n",
      "1965 Johnson-2:   0\n",
      "1966 Johnson:     0\n",
      "1967 Johnson:     2\n",
      "1968 Johnson:     3\n",
      "1969 Johnson:     0\n",
      "1970 Nixon:       0\n",
      "1971 Nixon:       1\n",
      "1972 Nixon:       0\n",
      "1973 Nixon:       1\n",
      "1974 Nixon:       0\n",
      "1975 Ford:        0\n",
      "1976 Ford:        3\n",
      "1977 Ford:        0\n",
      "1978 Carter:      1\n",
      "1979 Carter:      2\n",
      "1980 Carter:      0\n",
      "1981 Reagan:      4\n",
      "1982 Reagan:      0\n",
      "1983 Reagan:      2\n",
      "1984 Reagan:      1\n",
      "1985 Reagan:      1\n",
      "1986 Reagan:      1\n",
      "1987 Reagan:      1\n",
      "1988 Reagan:      2\n",
      "1989 Bush:        2\n",
      "1990 Bush:        2\n",
      "1991 Bush-1:      0\n",
      "1991 Bush-2:      0\n",
      "1992 Bush:        3\n",
      "1993 Clinton:     1\n",
      "1994 Clinton:     2\n",
      "1995 Clinton:     1\n",
      "1996 Clinton:     1\n",
      "1997 Clinton:     1\n",
      "1998 Clinton:     4\n",
      "1999 Clinton:     1\n",
      "2000 Clinton:     3\n",
      "2001 GWBush-1:    1\n",
      "2001 GWBush-2:    0\n",
      "2002 GWBush:      0\n",
      "2003 GWBush:      3\n",
      "2004 GWBush:      2\n",
      "2005 GWBush:      2\n",
      "2006 GWBush:      0\n"
     ]
    }
   ],
   "source": [
    "for u, w in zip(su.fileids(), devil_words):\n",
    "    print(u[:4], u[5:-4] + \":\" +\n",
    "          \" \" * (width - len(u[5:-4])),  \"{:>2}\".format(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__c.__ Since strings are immutable, we need to convert whatever format the `text` is in to a list. From there, we have several ways to choose words at random.  I originally chose $n$% of the index values at random and replaced those words.  But this was very slow with large texts, as the interpreter would have to traverse the entire list of words to find the word to be replaced.  I settled on the method below, which is much quicker: The interpreter only goes through the list of words once, and returns a random number between 0.0 and 1.0 for each word.  If the random number is below a certain threshold, the word is replaced.  With this method, there is a decent chance that the percentage of words replaced will differ from the percentage we specify, since the chances of one word being replaced are independent of all other words (i.e., as long as the threshold is not 0% or 100%, there's a chance that none of the words will be replaced, and also a chance that all of the words will be replaced).  Also, punctuation will never be replaced, since these marks don't have values in the dictionary `letter_vals`, which we use in the `gematria` function.*\n",
    "\n",
    "*Also using a function I used in [Chapter 2](https://github.com/Sturzgefahr/Natural-Language-Processing-with-Python-Analyzing-Text-with-the-Natural-Language-Toolkit/tree/master/Chapter%2002 \"Chapter 2 Exercises\") - `join_punctuation` - to reattach punctuation that was separated during tokenizing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def join_punctuation(text, characters = [\"'\", '’', ')', ',', '.', ':', ';', '?', '!', ']', \"''\"]): \n",
    "    \"\"\"\n",
    "    Takes a list of strings and attaches punctuation to\n",
    "    the preceding string in the list.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = iter(text)\n",
    "    current = next(text)\n",
    "\n",
    "    for nxt in text:\n",
    "        if nxt in characters:\n",
    "            current += nxt\n",
    "        else:\n",
    "            yield current\n",
    "            current = nxt\n",
    "            \n",
    "\n",
    "    yield current\n",
    "\n",
    "def decode(text, n = 10):\n",
    "    \"\"\"\n",
    "    Returns a copy of the original text with n percent\n",
    "    of the words converted into its gematria form.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    text: Text can be any form. Will be converted into a list.\n",
    "    n:    Percentage of the words to be converted.  Should be\n",
    "          an integer between 0 and 100.   \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # convert a cp of text into a list\n",
    "    if type(text) == str:\n",
    "        # use tokenize to separate punctuation from words\n",
    "        cp = word_tokenize(text)    \n",
    "    elif type(text) == list:\n",
    "        cp = text[:]    \n",
    "    else:\n",
    "        cp = list(text[:])\n",
    "        \n",
    "\n",
    "    # go through the words in the list,\n",
    "    # and return a random number;\n",
    "    # if the random number is less than the percentage\n",
    "    # replace the word with its gematria value\n",
    "    for i in range(len(cp)):\n",
    "        if random.random() <= n/100: \n",
    "            cp[i] = str(gematria(cp[i]))\n",
    "        \n",
    "    \n",
    "    # using join punctuation to rejoin punctuation separated during\n",
    "    # tokenizing\n",
    "    return ' '.join(join_punctuation(cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'318 is just a 1105 to 310 90 my code 870 work'"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(\"This is just a test to see if my code will work\", 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0 GEORGE W 0 0' S 0 BEFORE A JOINT SESSION OF THE CONGRESS 0 0 STATE OF 0 UNION January 0 0 0 THE PRESIDENT: Thank you all. Mr. 311, Vice President Cheney, members 150 Congress, members 150 the Supreme 676 55 diplomatic corps, distinguished guests 0 55 1015 785 0 Today our nation lost a beloved, graceful, courageous woman 878 73 America to 710 founding ideals and 423 on a 157 250 0 Tonight we are comforted 12 the 163 of a 38 391 1218 the husband who 1101 476 so long ago 0 and we are 725 for the 147 life 150 Coretta 873 63. ( 502 .) President George W 0 Bush reacts to applause during his State of 413 Union Address at the 591, Tuesday, Jan. 0, 0. White 381 photo by 213 707 time I' 40 485 to this 1216, I' 40 humbled 12 413 privilege 0 55 mindful of the history we 0 11 360 1091. 5 have 626 under 718 591 dome in moments of national mourning and national 533. We 20 520 America through one of the 810 consequential periods of our history -- and it 309 been 50 honor 470 serve 1218 86. In a syst\""
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(su.words('2006-GWBush.txt'), 33)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0 81 by Jane Austen 0 0 VOLUME I CHAPTER I Emma 533, handsome, clever 0 55 rich, with 1 comfortable home and happy disposition 0 seemed 470 471 some of the 707 blessings of existence; and 13 lived nearly twenty - one 516 in the world 1218 very little to 1519 270 71 her 0 She 1101 the youngest of the two daughters of a 810 affectionate, 558 father; and 13, in consequence 150 her sister' s marriage, 62 mistress of his 389 from 1 221 early period. Her 723 had 23 540 153 74 for 213 470 have more 459 an indistinct remembrance of her caresses; and 213 place had been supplied 12 an excellent woman as 939 0 878 had 196 little 978 of a 723 in affection 0 530 years had Miss Taylor been 60 Mr. Woodhouse' s 171, less as 1 939 459 a friend, very 204 150 480 daughters, but particularly of Emma. Between _them_ 410 was 315 the 524 of sisters 0 Even 362 Miss Taylor 13 ceased to hold the nominal office of 939, the mildness of 213 temper 13 hardly allowed her to impose 61 restraint 0 and 413 1183 150 110\""
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(nltk.corpus.gutenberg.words('austen-emma.txt'), 30)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 17. \n",
    "\n",
    "◑ Write a function `shorten(text, n)` to process a text, omitting the $n$ most frequently occurring words of the text. How readable is it?\n",
    "\n",
    "*The texts are usually quite readable if we delete the most common words, as most of these common words will be stop words.  However, in news articles and novels some of the most common words will be the names of the principals, and without those it's impossible to know who's doing what.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "\n",
    "def join_punctuation(text, characters = [\"'\", '’', ')', ',', '.', ':', ';', '?', '!', ']', \"''\"]): \n",
    "    \"\"\"\n",
    "    Takes a list of strings and attaches punctuation to\n",
    "    the preceding string in the list.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = iter(text)\n",
    "    current = next(text)\n",
    "\n",
    "    for nxt in text:\n",
    "        if nxt in characters:\n",
    "            current += nxt\n",
    "        else:\n",
    "            yield current\n",
    "            current = nxt\n",
    "            \n",
    "\n",
    "    yield current\n",
    "\n",
    "\n",
    "def shorten(text, n):\n",
    "       \n",
    "    # convert a cp of text into a list\n",
    "    if type(text) == str:\n",
    "        # use tokenize to separate punctuation from words\n",
    "        cp = word_tokenize(text)    \n",
    "    elif type(text) == list:\n",
    "        cp = text[:]    \n",
    "    else:\n",
    "        cp = list(text[:])\n",
    "        \n",
    "    # get a list of most common words, and strip away the counts\n",
    "    most_common = [w for w, _ in nltk.FreqDist(w for w in cp if w.isalpha()).most_common(n)]\n",
    "    \n",
    "    # replace most common words\n",
    "    for i in range(len(cp)):\n",
    "        if cp[i] in most_common:\n",
    "            cp[i] = ''\n",
    "    \n",
    "    # join list and normalize whitespace - \n",
    "    # otherwise there'll be gaps for the missing words\n",
    "    # also use join_punctuation to reattach punctuation \n",
    "    # separate during tokenizing\n",
    "    return re.sub(r'\\s+', ' ', ' '.join(join_punctuation(cp)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This a test which a rather short one'"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(\"This is a test which is a rather short one\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PRESIDENT GEORGE W. BUSH' S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION January 31, 2006 THE PRESIDENT: Thank . Mr. Speaker, Vice President Cheney, members Congress, members Supreme Court diplomatic corps, distinguished guests, fellow citizens: Today lost beloved, graceful, courageous woman called its founding ideals carried noble dream. Tonight comforted hope glad reunion husband was taken so long ago, grateful good life Coretta Scott King. ( .) President George W. Bush reacts applause during his State Union Address Capitol, Tuesday, Jan. 31, 2006. White House photo Eric DraperEvery time ' m invited rostrum, ' m humbled privilege, mindful history ' ve seen together. gathered under Capitol dome moments national mourning national achievement. served through one most consequential periods history -- been my honor serve . system two parties, two chambers, two elected branches, there always differences debate. But even tough debates conducted civil tone, differ\""
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(su.words('2006-GWBush.txt'), 50)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ Jane Austen 1816] VOLUME CHAPTER Woodhouse, handsome, clever, rich, comfortable home happy disposition, seemed unite some best blessings existence; lived nearly twenty - one years world little distress or vex . youngest two daughters most affectionate, indulgent father; , consequence sister' marriage, mistress house early period. Her mother died too long ago more than an indistinct remembrance caresses; place supplied an excellent woman governess, who fallen little short mother affection. Sixteen years Taylor . Woodhouse' family, less governess than friend, fond both daughters, particularly . Between _them_ more intimacy sisters. Even before Taylor ceased hold nominal office governess, mildness temper hardly allowed impose restraint; shadow authority being now long passed away, they living together friend friend mutually attached, doing just what liked; highly esteeming Taylor' judgment, directed chiefly own. The real evils, indeed, ' situation power having rather too much own way, d\""
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(nltk.corpus.gutenberg.words('austen-emma.txt'), 50)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we delete an additional 50 common words, we'll lose mentions of \"Woodhouse\", one of the principal characters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ Austen 1816] VOLUME CHAPTER , handsome, clever, rich, comfortable home happy disposition, seemed unite some best blessings existence; lived nearly twenty - years world distress vex . youngest two daughters most affectionate, indulgent father; , consequence sister' marriage, mistress house early period. Her mother died too long ago indistinct remembrance caresses; place supplied excellent woman governess, fallen short mother affection. Sixteen years Taylor . ' family, less governess friend, fond both daughters, particularly . Between _them_ intimacy sisters. Even before Taylor ceased hold nominal office governess, mildness temper hardly allowed impose restraint; shadow authority long passed away, living together friend friend mutually attached, doing just liked; highly esteeming Taylor' judgment, directed chiefly . real evils, indeed, ' situation power having rather too way, disposition too ; these disadvantages threatened alloy many enjoyments. danger, however, present unperceived, m\""
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(nltk.corpus.gutenberg.words('austen-emma.txt'), 100)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18.\n",
    "\n",
    "◑ Write code to print out an index for a lexicon, allowing someone to look up words according to their meanings (or pronunciations; whatever properties are contained in lexical entries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Don't really understand what I'm supposed to do.*\n",
    "\n",
    "*Maybe I need to sort the dictionary by keys?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "\n",
    "d = {}\n",
    "\n",
    "for w, v in entries:\n",
    "    key = ''.join(v)\n",
    "    d.setdefault(key, []).append(w)\n",
    "    \n",
    "indexed = [[i + 1, (k, v)] for i, (k, v) in enumerate(d.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for w, v in entries:\n",
    "    key = ''.join(v)\n",
    "    d.setdefault(key, []).append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = [[i + 1, (k, v)] for i, (k, v) in enumerate(d.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-519-9a2a21f7d640>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "sorted(d.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
